<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en-US">

<head>
<link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600' rel='stylesheet' type='text/css'>
<link rel="icon" type="x-icon" href="img/logo_small.jpg" />
<title>Frontier Vision Lab (FVL)</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="style.css" type="text/css" media="screen">
<style>
	body{
		background-image:url(img/网页背景1.png);
		background-attachment:fixed;
	}
</style>
</head>

<body>
<div id="wrapperhead">
<div id="header">
  <div class="logom"><img src="img/中山大学透明logo.png" alt="SYSU's LOGO" width="320" height="100"></div>
  <h1><a href="index.html">Frontier Vision Lab (FVL)</a></h1>
</div>

<div id="wrapperindex">
<div id="container">
  <div id="about">
	  <h4></h4>
	  <h4>jinzh26[at]mail.sysu.edu.cn</h4>
	<br>
    <p>The Frontier Vision Lab (FVL) is leaded by Associate Professor <a href="http://ise.sysu.edu.cn/teacher/teacher02/1384977.htm"><font color=#c50000>Zhi Jin</font></a> with the School of Intelligent Systems Engineering, Sun Yat-sen University. FVL currently performs research in the fields of Image/video Quality Enhancement, Object Detection, 3D Reconstruction, and Image-based Healthy Measurement. </p><br>
    <p>The Frontier Vision Lab aims to treat the complete cycle from images to their interpretation, and to the resulting action. It is our objective to develop universal concepts and methods. In order to meet these challenges, we want to keep our finger at the pulse of international, ongoing research and we operate in the context of many collaborations with other labs and projects. </p>
	<br>
    <p>This said, it simultaneously is our strategy to let difficult, real-world applications drive our research and development. We see collaboration with industry as an important plus for an engineering lab like ours.</p><br>
  </div> 
   
  <div class="centered-element", id="photo"> <img src="img/whole_lab_new.jpg" alt="FVL's Profile Picture" width="400" height="520"> </div>
  <p>&nbsp;</p>
</div>
</div>


<div id="container">
<div id ="mainbody">

<h3>News: </h3>
<ul>
<li>&loz; We participateed the <a href="https://cvlai.net/ntire/2024/"><font color=#c50000>9th edition of CVPR2024 workshop NTIRE: New Trends in Image Restoration and Enhancement challenge</font> </a> and won <font color=#c50000>first place</font> among 427 participants. </li>
<li>&loz; Our paper "Dynamic Implicit Image Function for Efficient Arbitrary-Scale Super-Resolution" was accepted by <a href="https://2024.ieeeicme.org/"><font color=#c50000>ICME 2024</font></a>. </li>
<li>&loz; Our paper "CAPformer: Compression-Aware Pre-trained Transformer for Low-Light Image Enhancement" was accepted by <a href="https://2024.ieeeicme.org/"><font color=#c50000>ICME 2024</font></a>. </li>
<li>&loz; Our paper "Latent Modulated Function for Computational Optimal Continuous Image Representation" was accepted by <a href="https://cvpr.thecvf.com/"><font color=#c50000>CVPR 2024</font></a>. </li>
<li>&loz; Our paper "Learning from Text: A Multimodal Face Inpainting Network for Irregular Holes" was accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76"><font color=#c50000>IEEE Transactions on Circuits and Systems for Video Technology</font></a>. </li>
<li>&loz; Our paper "Reconstruction with robustness: A semantic prior guided face super-resolution framework for multiple degradations" was accepted by <a href="https://www.sciencedirect.com/science/article/abs/pii/S0262885623002317"><font color=#c50000>Image and Vision Computing</font></a>. </li>
<li>&loz; December 15, 2023 Professor Weisi Lin, visited our lab and <a href="https://github.com/FVL2020/fvl.github.com/tree/master/news/Weisi%20Lin"><font color=#c50000>gave a talk</font></a>. <br> </li>
<li>&loz; October 20, 2023 Scholar Chao Dong, the first author of SRCNN, visited our lab and <a href="https://github.com/FVL2020/fvl.github.com/tree/master/news/Dong%20Chao"><font color=#c50000>gave a talk</font></a>. <br> </li>
<li>&loz; September 2023, the Sino-German Mobility Project Joint Exchange <a href="https://github.com/FVL2020/fvl.github.com/tree/master/news/SG_again"><font color=#c50000>Meeting was successfully held again</font></a>.</li>
<li>&loz; Our paper "MB-TaylorFormer: Multi-branch Efficient Transformer Expanded by Taylor Formula for Image Dehazing" was accepted by <a href="https://iccv2023.thecvf.com/"><font color=#c50000>ICCV 2023</font></a>. </li>
<li>&loz; Our papers "FourLLIE: Boosting Low-Light Image Enhancement by Fourier Frequency Information" and "Brighten-and-Colorize: A Decoupled Network for Customized Low-Light Image Enhancement" were accepted by <a href="https://www.acmmm2023.org/"><font color=#c50000>ACM MM 2023</font></a>. </li>
<li>&loz; We participated the <a href="https://cvlai.net/ntire/2023/"><font color=#c50000>8th edition of CVPR2023 workshop NTIRE: New Trends in Image Restoration and Enhancement challenge</font> </a> and won 2nd place among final 93 participants. </li>
<li>&loz; March 2023, the Sino-German Mobility Project Joint Exchange <a href="https://github.com/FVL2020/fvl.github.com/tree/master/news/Xu%20Xiao"><font color=#c50000>Meeting was successfully held</font></a>.</li>
<li>&loz; We participated the <a href="http://cvpr2022.ug2challenge.org/"><font color=#c50000>5th edition of CVPR2022 UG2+ Challenge: BRIDGING THE GAP BETWEEN COMPUTATIONAL PHOTOGRAPHY AND VISUAL RECOGNITION</font> </a> and won 4th place among final 20 participants. </li>
<li>&loz; We participated the <a href="https://data.vision.ee.ethz.ch/cvl/ntire21/"><font color=#c50000>6th edition of CVPR2021 workshop NTIRE: New Trends in Image Restoration and Enhancement challenge</font> </a> and won 11th place among 200+ participants. </li>
<li>&loz; We participated the <a href="https://data.vision.ee.ethz.ch/cvl/ntire20/"><font color=#c50000>5th edition of CVPR2020 workshop NTIRE: New Trends in Image Restoration and Enhancement challenge</font> </a> and won 7th place among 286 participants. </li>
</ul>

<a  name="publication">&nbsp; </a>
<h3>Publications: </h3>
<table border=0 cellpadding=0 width=100% cellspacing="10" style="line-height:18pt;  border-spacing: 60 6px;">
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/fastScene.png" width=256> </div> </td>
    <td>
    <p> Yikun Ma, Dandan Zhan, Zhi Jin*<br>
      <b><em>FastScene: Text-Driven Fast 3D Indoor Scene Generation via Panoramic Gaussian Splatting</em></b><br>
      Proceedings of the 33rd International Joint Conference on Artificial Intelligence (IJCAI) 2024. <font color=#c50000>Oral Paper</font> <br>
	  <a href="https://arxiv.org/abs/2405.05768"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/Mr-Ma-yikun/FastScene"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
	<!-- 这是一个空行 -->
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/LMF-based.png" width=256> </div> </td>
    <td>
    <p> Zongyao He, Zhi Jin*<br>
      <b><em>Latent Modulated Function for Computational Optimal Continuous Image Representation</em></b><br>
      2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). <font color=#c50000>Hightlight Paper</font> <br>
	  <a href="https://arxiv.org/abs/2404.16451"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/HeZongyao/LMF"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
	<!-- 这是一个空行 -->
<tr>
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/DIIF.png" width=256> </div> </td>
    <td>
    <p> Zongyao He, Zhi Jin*<br>
      <b><em>Dynamic Implicit Image Function for Efficient Arbitrary-Scale Image Representation</em></b><br>
      Proceedings of the IEEE International Conference on Multimedia & Expo (ICME) 2024.  <br>
	  <a href="https://arxiv.org/abs/2306.12321"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/RSemFace"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
	<!-- 这是一个空行 -->
</tr>
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/MuFIN.png" width=256> </div> </td>
    <td>
    <p> Dandan Zhan, Jiahao Wu, Xing Luo, Zhi Jin*<br>
      <b><em>Learning from Text: A Multimodal Face Inpainting Network for Irregular Holes</em></b><br>
      IEEE Transactions on Circuits and Systems for Video Technology.  <br>
	  <a href="https://ieeexplore.ieee.org/abstract/document/10445705"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/MuFIN"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
    <!-- 这是一个空行 -->
</tr>
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/RSemFace.png" width=256> </div> </td>
    <td>
    <p> Hongjun Wu, Haoran Qi, Huanrong Zhang, Zhi Jin*, Driton Salihu, and Jian-Fang Hu<br>
      <b><em>Reconstruction with robustness: A semantic prior guided face super-resolution framework for multiple degradations</em></b><br>
      Image and Vision Computing. <br>
	  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0262885623002317"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/RSemFace"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
    <!-- 这是一个空行 -->
</tr>
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/FourLLIE.png" width=256> </div> </td>
    <td>
    <p> Chenxi Wang, Hongjun Wu, and Zhi Jin*<br>
      <b><em>FourLLIE: Boosting Low-Light Image Enhancement by Fourier Frequency Information</em></b><br>
      Proceedings of the 31th ACM International Conference on Multimedia (ACM MM) 2023. <br>
	  <a href="https://arxiv.org/pdf/2308.03033.pdf"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/FourLLIE"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
    <!-- 这是一个空行 -->
</tr>	
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/Brighten-and-Colorize.png" width=256> </div> </td>
    <td>
    <p> Chenxi Wang, and Zhi Jin*<br>
      <b><em>Brighten-and-Colorize: A Decoupled Network for Customized Low-Light Image Enhancement</em></b><br>
      Proceedings of the 31th ACM International Conference on Multimedia (ACM MM) 2023. <br>
	  <a href="https://arxiv.org/pdf/2308.03029v1.pdf"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/BCNet"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
    <!-- 这是一个空行 -->
</tr>	
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/MB-TaylorFormer.png" width=256> </div> </td>
    <td>
    <p> Yuwei Qiu, Kaihao Zhang, Chenxi Wang, Wenhan Luo, and Zhi Jin*<br>
      <b><em>MB-TaylorFormer: Multi-branch Efficient Transformer Expanded by Taylor Formula for Image Dehazing</em></b><br>
      Proceedings of the IEEE International Conference on Computer Vision (ICCV) 2023. <br>
	  <a href=""><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/ICCV-2023-MB-TaylorFormer"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
    <!-- 这是一个空行 -->
</tr>
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/V-DixMatch.png" width=256> </div> </td>
    <td>
    <p> Chenxi Wang, Jingzhou Luo, Xing Luo, Haoran Qi and Zhi Jin*<br>
      <b><em>V-DixMatch: A Semi-Supervised Learning Method for Human Action Recognition in Night Video Sensing</em></b><br>
      IEEE Sensors Journal 2023. <br>
	  <a href="https://ieeexplore.ieee.org/abstract/document/10184205"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/V-Dixmatch-Sensors"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
    <!-- 这是一个空行 -->
</tr>	
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/ELSFace.png" width=256> </div> </td>
    <td>
    <p> Haoran Qi, Yuwei Qiu, Xing Luo, and Zhi Jin*<br>
      <b><em>An Efficient Latent Style Guided Transformer-CNN Framework for Face Super-Resolution</em></b><br>
      IEEE Transactions on Multimedia 2023. <br>
	  <a href="https://ieeexplore.ieee.org/document/10145603"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/ELSFace"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
    <!-- 这是一个空行 -->
</tr>	
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/IEDCN.png" width=256> </div> </td>
    <td>
    <p> Hongjun Wu, Haoran Qi, Jingzhou Luo, Yining Li, and Zhi Jin*<br>
      <b><em>A Lightweight Image Entropy-Based Divide-and-Conquer Network for Low-Light Image Enhancement</em></b><br>
      Proceedings of the IEEE International Conference on Multimedia & Expo (ICME) 2022. <br>
	  <a href="https://ieeexplore.ieee.org/document/9859785"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/IEDCN"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
    <!-- 这是一个空行 -->
</tr>	
 <tr>
    <td height=135> <div id="paperphoto"> <img src="paper/BMI_TMM.png" width=256> </div> </td>
    <td>
    <p> Zhi Jin, Junjia Huang, Wenjin Wang, Aolin Xiong, Xiaojun Tan*<br>
      <b><em>Estimating Human Weight from A Single Image</em></b><br>
      IEEE Transactions on Multimedia (TMM), EARLY ACCESS, 2022. <br>
	  <a href="https://ieeexplore.ieee.org/document/9699418"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/2DImage2BMI"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
    <!-- 这是一个空行 -->
</tr>
 <tr>
    <td height=135> <div id="paperphoto"> <img src="paper/BMI_PRL.png" width=256> </div> </td>
    <td>
    <p> Zhi Jin, Junjia Huang, Aolin Xiong, Yuxian Pang, Wenjin Wang, Beichen Ding*<br>
      <b><em>Attention guided deep features for accurate body mass index estimation</em></b><br>
      Elsevier, Pattern Recognition Letters, 154, pp.22-28, 2022. <br>
	  <a href="https://www.sciencedirect.com/science/article/pii/S0167865522000022"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/2DImageBMIestimationEnd2End"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>	
<tr>
    <!-- 这是一个空行 -->
</tr>
 <tr>
    <td height=135> <div id="paperphoto"> <img src="paper/SRDRL.png" width=256> </div> </td>
    <td>
    <p> Zongyao He, Zhi Jin*, Yao Zhao<br>
      <b><em>SRDRL: A Blind Super-Resolution Framework With Degradation Reconstruction Loss</em></b><br>
      IEEE Transactions on Multimedia (TMM), Volume: 24, 2021. <br>
	  <a href="https://ieeexplore.ieee.org/document/9459506"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/SRDRL"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
    <!-- 这是一个空行 -->
</tr>
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/AttrFaceNet.jpg" width=256> </div> </td>
    <td>
    <p> Jie Xiao, Dandan Zhan, Haoran Qi, Zhi Jin*<br>
      <b><em>When Face Completion Meets Irregular Holes: an Attributes Guided Deep Inpainting Network</em></b><br>
      Proceedings of the 28th ACM International Conference on Multimedia (ACM MM). 2021. <br>
	  <a href="https://dl.acm.org/doi/10.1145/3394171.3413664"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/AttrFaceNet"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
    <!-- 这是一个空行 -->
</tr>	
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/Huang_ICME2021.jpg" width=256> </div> </td>
    <td>
    <p> Junjia Huang, Chenming Shang, Aolin Xiong, Yuxian Pang, Zhi Jin*<br>
      <b><em>SEEING HEALTH WITH EYES: FEATURE COMBINATION FOR IMAGE-BASED HUMAN BMI ESTIMATION</em></b><br>
      Proceedings of the IEEE International Conference on Multimedia & Expo (ICME) 2021. <br>
	  <a href=""><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/Features_for_BMI_estimation"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
    <!-- 这是一个空行 -->
</tr>	
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/Xiao_SPIM2021_SWCNN.png" width=256> </div> </td>
    <td>
    <p> Jie Xiao, Zhi Jin*, Huanrong Zhang<br>
      <b><em>A general model compression method for image restoration network</em></b><br>
      Signal Processing: Image Communication. 2021. <br>
	  <a href="https://doi.org/10.1016/j.image.2021.116134"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/FVL2020/SW_ModelCompression"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
    <!-- 这是一个空行 -->
</tr>	
 <tr>
    <td height=135> <div id="paperphoto"> <img src="paper/zhang_jstsp_mswsr.png" width=256> </div> </td>
    <td>
    <p> Huanrong Zhang, Jie Xiao, Zhi Jin*<br>
      <b><em>Multi-scale Image Super-Resolution via A Single Extendable Deep Network</em></b><br>
      IEEE Journal of Selected Topics in Signal Processing (JSTSP). 2021. <br>
	  <a href="https://doi.org/10.1109/JSTSP.2020.3045282"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/supercaoO/MSWSR"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
<tr>
    <!-- 这是一个空行 -->
</tr>	
<tr>
    <td height=135> <div id="paperphoto"> <img src="paper/zhang_acmmm20_wsr.png" width=256> </div> </td>
    <td>
    <p> Huanrong Zhang, Zhi Jin*, Xiaojun Tan, Xiying Li<br>
      <b><em>Towards Lighter and Faster: Learning Wavelets Progressively for Image Super-Resolution</em></b><br>
      Proceedings of the 28th ACM International Conference on Multimedia (ACM MM). 2020. <br>
	  <a href="https://dl.acm.org/doi/10.1145/3394171.3413664"><font color=#c50000>[paper]</font></a>
	  <a href="https://github.com/supercaoO/WSR"><font color=#c50000>[code]</font></a>
    </p>
    </td>
</tr>
  </table>
 
<a  name="misc">&nbsp; </a>
<h2>Misc:</h2>
  
<div id="footer">
  <p> <center> Last update on February 2021.
  </center></p>
</div>       
</div>
</div>
</div>
</body>

</html>

